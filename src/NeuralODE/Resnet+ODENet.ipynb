{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn, autograd, optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from NeuralODE.neural_ode_solvers import AdjointODE\n",
    "from NeuralODE.odenet import ResidualBlock, ODEBlock, MNISTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('../PATH_TO_STORE_TRAINSET', train=True, transform=transform)\n",
    "testset = datasets.MNIST('../PATH_TO_STORE_TESTSET', train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that optimizes a model\n",
    "def train(model, epochs, print_epochs=False):\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    time0 = time()\n",
    "    losses = []\n",
    "    for e in tqdm(range(epochs)):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            #This is where the model learns by backpropagating\n",
    "            loss.backward()\n",
    "\n",
    "            #And optimizes its weights here\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        losses.append(running_loss/len(trainloader))\n",
    "        if print_epochs:\n",
    "            print(\"Epoch {} - Training loss: {}\".format(e, losses[-1]))\n",
    "    print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that returns loss and accuracy of a model on the test set\n",
    "def test(model):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for image, labels in testloader:\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, labels)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        test_loss = float(test_loss)\n",
    "        correct = 100. * float(correct) / len(testloader.dataset)\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ResNet\n",
    "\n",
    "In our architechture we have a structure of a convolutional layer, two sequential resnet blocks and a maxpool layer repeating 4 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet = MNISTClassifier(ResidualBlock).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [06:15<00:00, 24.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Time (in minutes) = 6.250414184729258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(resnet, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0005774503806605935, 99.26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ODENet\n",
    "The same architechture as the ResNet model, but with ODENet blocks instead of ResNet blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odenet = MNISTClassifier(ODEBlock).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [13:52<00:00, 55.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Time (in minutes) = 13.878390876452128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(odenet, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0008329695556312799, 98.78)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(odenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We can see that ODENet shows relatively the same quality as ResNet with the same architechture on the MNIST dataset. We can draw the conclusion that substituding discrete time in a generative model with a continues time flow doesn't affect the quality and can be used. \n",
    "\n",
    "In our case the ODENet model did take more time to train, but theoretical estimations show that both models have the same training time of O(L).\n",
    "\n",
    "Authors of https://arxiv.org/pdf/1806.07366.pdf have also experimented with MNIST dataset and, same as in our case, ODENet didn't outperform ResNet but showed similar accuracy. The signinficant difference of the models is that ODENet requires O(1) memory whereas ResNet takes O(L), where L is the number of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
